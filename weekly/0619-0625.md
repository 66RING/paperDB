# other

开门造车APP

乐子的, 认真的, 头脑风暴的

探索计算和传输overlap的优化。目前想法是使用AI编译器的方法识别模式后生成新的计算图。

1. 总结几种overlap的方法, 以便后续能应用到子图替换中。
2. 阅读msccl解释器代码, 熟悉集合通信算法由图到实际算法的实现方法。
3. 阅读metaflow代码, 熟悉计算图的搜索, 替换以及优化的原理和实现。
4. 参考Unity对计算和传输的计算图表示, 熟悉自动并行的实现和原理。


# idea

**搞自动并行/搜索相关的, 因为那才能和图计算有所联系**

- **分布式图优化 + 图分割**
    * 但可能不是那么well motivated, 但是我觉得有些东西不是那么straight forward的, 比如GPT这种原理
    * 一个motivated可以是方便研究员做研究
- 图优化的本质有点像 走迷宫
- taccl就是想把图优化应用到集合通信上吧，只不过只有拓扑没有图, 所以就定了个所谓的通信草图然后在草图上优化
- 图计算公开课 -> 解决一个实际的ml问题(metaflow)
- 异构分布式 + 图优化: A100 + V100


- idea
    * the sys
        + virutal block (ipart)
        + reorder and 常量压缩 (Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models)
        + DSL abs compiler (coconet)
        + 不规则流水线
    * overlap的本质是生产者消费者模型
    * 基于图算法的搜索空间优化
        + 关系引入了隐秘信道
    * 自动并行目前主要都在关注布局上的问题, 那overlap上的自动并行有人在乎吗?(异构拓扑, taccl?)
        + 用户可以根据需要自定义算法(msccl)
        + cc算法可以overlap
        + 两者结合出一个图优化概念
    * **分布式图优化????**: 编译不再是在单机上进行!!!!!来多大的搜索空间都可以
        + 抽象一下图优化的模式
    * 冗余显存但速度翻X倍, **显存的宿命会和内存一样**
    * 计算草图可行?
    * 不规则切分, 类似(OSP)
    * **分布式图优化 + 图分割**
- cons
    * 不规则流水线和virtual block有点互斥, 空闲空间只能被一种方法填满


- device mapping: 代理操作
- ccl内存管理, 多级存储虚拟存储机制
- 自动张量并行 -> 虚拟块 -> 自动常量展开


## 2023-06-25

### TASO: Optimizing Deep Learning Computation with Automatic Generation of Graph Substitutions

> [rust版](https://github.com/uwplse/tensat)

> 论点: 子图转换需要专家手动编写src和dst不可扩展且可能错过潜在优化

它将 **operator specifications** 作为输入，生成一系列可替换的子图 candidates, 利用自动的 theorem prover来通过形式化验证筛选，最后使用cost-based 回溯搜索法来找到最优图

使用：

```python
import taso
import onnx

old_model = taso.load_onnx("/path/to/load/onnx/model")
taso_graph = taso.optimize(old_model)
new_model = taso.export_onnx(taso_graph)
onnx.save(new_model, "/path/to/save/new/onnx/model")
```

- 自动生成替换子图, 回溯算法, 损失模型
- 核心组件: 子图替换生成器，验证器，联合优化器
    * Generating substitutions: 枚举 + 初筛
        1. 枚举所有子图到一个fixed size。
        2. 给一系列随机输入对比输出初步筛选, 利用hash表(fingerprint)快速找相同输出的子图
    * Formal verification:
        1. 用户提供operator properties(如线性性等数学性质), 来做形式化认证(table 2). 用theorem prover
    * 联合优化: 同一表示子图替换和**数据布局**
        1. Metaflow的cost model基础上额外考虑不同布局的cost


> 什么是operator specifications?

primitive operators + operator properties(如线性性等数学性质)

因为自动生成是基于用户指定的a list of primitive operators生成的。


> 怎么无中生有自动生成子图替换?

同样metaflow的替换方法

1. source graph
2. target graph
3. in/output mapping

Generation Algorithm(S2.2):

> 不同layout怎么枚举??

基于硬件


### Unity source code:

```
register_flexflow_internal_tasks 

FFModel::compile -> TaskLauncher launcher(GRAPH_OPTIMIZE_TASK_ID)
-> graph_optimize_task -> try_one_lambda -> graph_optimize
```


### Unity: Accelerating DNN Training Through Joint Optimization of Algebraic Transformations and Parallelization

> 代数-并行联合优化, as substitutions on a unified parallel computation graph (PCG),
> 包括优化计算, 并行和传输
>
> Unity的很多引用都值得看一下

source code: flexflow的PCG模块

- terms:
    * A变(Algebraic transformations), P变(Parallelization transformations)

- 基于子图替换, 但抽象成了PCG(parallel computation graph)
- **抽象出了3对operator**: Figure 8: Parallelization operators in Unity
    * Partition and combine
    * Replicate and Reduce
    * Pipeline and Batch
- **Figure 2**, TODO: review
- 两个挑战: A变要在P变前但会丢失一些可能的优化；搜索算法的可扩展性问题
- 实现 
    * pcg表示, a hierarchical search algorithm来识别哪个算法表现好
    * 转换生成和验证
        + A变 + P变
        + IR中间表示
- intro
    * A变: 混合, 重排. 详见TASO(ref 25)
    * P变: 6中主要模式
        + Data parallelism: replica of the entire model
        + Model parallelism: disjoint submodels
        + Spatial parallelism: 根据属性切分tensor, 比如RGB分成R, G, B
        + Reduction parallelism: "tensor并行"
        + Pipeline parallelism: 
        + Operator-specific parallelism

#### QA

- terms
    * fingerprint: 在一个固定输入下输出tensor的哈希值

> 搞清楚怎么联合优化的

把分布式相关的也抽象成节点(3对操作), 然后是metaflow中类似的子图匹配, "混合器"逐一尝试替换。


> 搞清楚P变是怎么用pcg表示并处理子图替换的

原始计算图的问题: 1. P变不是"增量的", 而A变随时会改变子图, 导致应用的P变失效, 即P变是把图看成static的。2. 传统计算图没有考虑到通信开销, 这在引入并行后是很重要的。

pcg中节点处理是operator也可以是parallelism的变化, 边除了是数据依赖还可以是数据移动。每个op都有一个mahcine mapping来提高图的表达能力。

也就是说parallel操作也成了图中的点和边

TODO Substitution generation.小段落: To do so, Unity adopts TASO’s super-optimization approach


> 怎么个hierarchical search algorithm(多级搜索算法)

Unity uses a three-level hierarchical search algorithm, depicted in Figure 12. => **分图(S5.3, 作为可扩展性的优化), 替换(S5.1), machine mapping(S5.2)**

- 子图替换的选择: metaflow的子图替换 + 选择"其一"
    * 同样的回溯算法做增量"改造", Unity uses the cost-based backtracking search algorithm from TASO
    * 改造次数到达一定阈值后, 取出PCG以生成新子图
    * 使用cost estimator测试与设备相关的cost
- TODO: 最优Machine Mapping搜索
    * Figure 13. 
    * TODO, 所以可以用动态规划来找最优解
    * TODO, review 5.2 Finding Optimized Machine Mappings
- 子图划分
    * **难点在于 划分成子图后, 一些整体才有的parallel的优化怎么处理**
        + Unity的解决办法就是简单的显式地专门地跨split查找, 那怎么保证可扩展性的?


> 带上parallel后cost model怎么算? 众所周知并行带来的可能是整体的性能提升, 所以单机上改怎么量化？

答案是一次测一批: a set of PCG

- 单个: 使用6种并行操作符来量化计算和传输的开销, 6种操作符组成对偶的3对:
    * Partition and combine
    * Replicate and Reduce
    * Pipeline and Batch
- 整体:
    * 通过per-iteration training time来量化


> 如何做子图替换

1. 启发式子图搜索
    - Substitution generation.
2. 复杂的形式验证保证正确
    - using an automated theorem prover (Z3 [12] in our implementation)

同Metaflow


> 好像说模式匹配是自动生成的？

好像说是用的TASO里的方法, 但源码中好像不是, 也是手动创建许多xfer。需要重看


## 2023-06-21


### Metaflow source code

> Figure 3 shows the main components of MetaFlow.
> 
> 只需要看懂make gpu的就行, 一个main入口


### OPTIMIZING DNN COMPUTATION WITH RELAXED GRAPH SUBSTITUTIONS(Metaflow)

> 非常详细, 非常适合初学者

> 传统图优化的贪心找"严格优", 这里想不要那么"严格优"行不行(relax), 更多可能性后可以带来整体更有的可能

> We introduce a backtracking search algorithm over a set of relaxed graph substitutions to find optimized networks
> and use a flow-based graph split algorithm to recursively split a computation graph into smaller subgraphs to
> allow efficient search

- 优化的示例: 多opt合一, 减少访存和kernel launch

搞清楚四个实现: 代价模型, 回溯算法, 图分割, 子图替换

核心函数: `optimize_graph`

#### 建图/读图


#### 代价模型

```cpp
class Model {
  void measure_conv2d_cost(Conv2D*);
  void measure_matmul_cost(Matmul*);
  void measure_pool2d_cost(Pool2D*);
  void measure_activation_cost(Activation*);
  void measure_batchnorm_cost(BatchNorm*);
  void measure_concat_cost(Concat*);
  void measure_split_cost(Split*);
  void measure_element_cost(Element*);
  void* allocate_memory(size_t size);
  float measure_oplist_runtime(const std::vector<OpBase*>& list);
};
```

> 本质就是跑一下, 采样一下。每个算子处记录一下cost

使用`collect_costs()`收集各个操作的runtime, mem, kernel launch。但比较时只考虑runtime(因为可能可以空间换时间), 使用`total_cost`

- runtime: 跑一下测一下
- mem: 人工计算, inputSize等
- kernle launch: 用到几个kernel, 一般++


#### 回溯算法

```cpp
  while (!candidates.empty()) {
    Graph *subGraph = candidates.top();
    candidates.pop();
    // 如果更优, 记录一下
    if (subGraph->total_cost() < bestCost) {
      delete bestGraph;
      bestCost = subGraph->total_cost();
      bestGraph = subGraph;
    }
    // 跳过不优
    if (subGraph->total_cost() > alpha * bestCost) {
      delete subGraph;
      continue;
    }
    // 搜索达到上限, 结束
    if (counter > budget) {
      break;
    }
    counter ++;
    // 使用各种混合器做一下子图替换, 更新candidates
    for (int i = 0; i < xfers.size(); i++)
      xfers[i]->run(0, subGraph, candidates, hashmap, bestCost * alpha, edgeWeights, firstGraph);
    firstGraph = false;
    if (bestGraph != subGraph) {
      delete subGraph;
    }
  }
```


#### 图分割



#### 子图替换

```cpp
  // NOTE: 混合器?
  xfers.push_back(create_fuse_conv_batch_xfer(model));
  xfers.push_back(create_fuse_mm_acti_xfer(model));
  xfers.push_back(create_fuse_conv_relu_xfer(model));
  xfers.push_back(create_merge_mm_xfer(model));
  xfers.push_back(create_merge_conv_xfer(model));
  xfers.push_back(create_exclusive_concat_xfer(model));
  xfers.push_back(create_resnet_merge_xfer(model));
```

核心函数: `xfers[i]->run(0, subGraph, candidates, hashmap, bestCost * alpha, edgeWeights, firstGraph);`


#### QA

> 所以, 怎么个relax法, 就是所有可能都尝试

We increase the space of optimizations considered by relaxing
the strict performance constraint, allowing any substitutions
that preserve semantics whether or not they improve performance.

> 那搜索空间怎么办? 回溯算法

To efficiently explore this larger
space of computation graphs, we use backtracking search
over a set of relaxed graph substitutions to find improved
networks after multiple substitution steps.

> 那现有的实现为什么不用回溯算法?

因为这里所谓的backtracking不是直接的回溯, 是做图切分然后再在子图上搜索, 并不一定是全局最优。子图是span少的

> 这么多种模式是怎么匹配然后替换的? S3? THE METAFLOW SEARCH ALGORITHM? TODO

- 不脱离数学等价性
- 一种type只能映射到一种type
- wildcard可以映射到任何type

TODO: 搜索算法, 剪枝+近似最优

- 搜索算法要素
    1. 代价模型: FLOPs, memory usage, and number of kernel launches
        - operator量化: 静态的 + 硬件相关的
            * 硬件相关的只记录部分有代表性的即可, ref. 一处采样到处使用
    2. 算法: backtracking + 细分子图 + 子图最优组合出全局最优
        1. cost优先队列, 小cost优先出
        2. G出队, 算新图G'入队
        3. 使用参数控制搜索时间和严格度, a越大搜索空间越大, a=1就只找严格优
            - a可以看成是cost的宽容度`Cost(G') < a * Cost(G)`
    3. Flow-Based Recursive Graph Split
        - TODO: redo

> ok, 搜索有了那怎么做子图替换呢? 即`G' = Si(G)`伪代码

TODO: 怎么做的子图替换呢???


### TODO: **Unity**

自动并行联合优化, **主要是考虑到了分布式的抽象**, -> 3.6x

TODO: review

- PCG(Parallel Computation Graph)

- **抽象出了3对operator**
    * Partition and combine
    * Replicate and Reduce
    * Pipeline and Batch


## 2023-06-20

### nccl allreduce算法详解

1. send to next GPU
    - 执行一次起个头
2. reduce and send result to next
    - 执行nrank - 2次，完成剩余的操作
3. TODO


### OSP: Overlapping Computation and Communication in Parameter Server for Fast Machine Learning

> PS机制: 在每个worker中计算梯度, 然后在ps中同步回传更新的参数
>
> Figure 3

- 对ps的优化, async但不降低loss趋势
- worker不在一push一pull一更新了, **而是可以自己先本地更新, 本地再计算**, 达到一定阈值后再push/pull
    * 怎么做到自己本地更新的? 如果可以本地更新还要ps干嘛
- result: **加速好 loss好**, 图4, 图5, 图6

idea: vblock为iter单位

TODO: code review

TODO: 好像

## 2023-06-19

### overlap

- byteps: cpu + gpu
    * In short, BytePS only uses NCCL inside a machine, while re-implements the inter-machine communication.
- coconet

- 方法总结
    * "不规则的流水线", 等待计算的时候塞点提前计算任务: ON OPTIMIZING THE COMMUNICATION OF MODEL PARALLELISM
    * 原语拆分流水线: coconet, Breaking the Computation and Communication Abstraction Barrier in Distributed Machine LearningWorkloads
        + 提供DSL以自定义
    * 不规则子任务, 从而能刚好填满等待的时间: Overlapping Communication With Computation in Parameter Server for Scalable DLTraining
    * TODO: Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models
        + 也是cc decompose into细粒度, 重组+交叉人为制造更多overlap
    * cpu + gpu资源利用: byteps


### coconet

- DSL
    * 扩展tensor概念, 新增layout的概念: sliced, replicated, and local 三种layout
        + sliced tensor is equally distributed among all nodes in a group along a specified dimension **with RANK identifying** the slice for that process.
        + replicated, across all ranks in a group where it has the same value on each rank and it does not have a rank identifier. (没有标识的sliced). 如bias等
        + local tensor has same shape on all ranks but different values on all ranks
    * 操作抽象(计算图): local computations和cross rank communication
    * 混合集合通信操作: TODO: S5.2
    * Overlapping Operations: S5.3
- **Coconet transformations**: 对所写DSL做优化(指令重排等)
    * split 分原语
        + AllReduce -> RS-AG: AllReduce into a ReduceScatter to produce a sliced tensor and an AllGather on the sliced tensor to return a replicated tensor.
    * reorder 重排
        + (scD , scOut , agOut ) = reorder (d, out , agSum )
    * fusing 重组: fuse multiple computations and communications in a single operation
        + Computation Fuse: 多个操作合并成一个
        + AllReduce Fuse: fuses a series of ReduceScatter, sliced computations, and AllGather operations in a single FusedAllReduce
    * overlapping 流水: to overlap a series of **producer-consumer operations** to utilize multiple resources of hardware simultaneously

TODO:

### Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models

> google

- Figure 4
    * "人为制造overlap", 重组 + 交叉, e.g. P1sum(a1)的时候异步发a0给P2, 然后P2sum(b0)发b1
    * compiler: 分片 + "常量合并"??


### Overlapping Communication With Computation in Parameter Server for Scalable DLTraining

> 分页以overlap, 但页面大小不固定更灵活从而刚好用满等待的时间

1. 采用通信和计算的时间
2. 根据采用结果用ai算法决定分片的大小策略


### msccl 解释器

> 似乎是比较简单的: 就是用xml描述每个gpu的任务（状态机）

- 遍历每个chunk: `+= chunkSize`
    * 等依赖项: flags
    * 执行每个step
    * 对于每个step向前执行cnt次`srcoffset = gridOffset + (ssize_t) (msccltran->srcoffset+c) * sizePerMscclChunk`
    * 处理每个step的算法: e.g. `MSCCL_REDUCE`
    * 更新flags


## last week TODO

- byteps
- msccl 带着问题看
    1. 调用哪个算法由谁决定
        - 添加标识符后都通过`runInterpreter()`同一解释
    2. 为什么ngpu会变化导致有时候成功有时候失败
        - TODO: 1. 因为每个节点都要执行相同的代码
    3. 算法怎么应用上nccl的
        - 用什么机制调用到`runInterpreter`的??
        - IMPL_COLL -> NCCL_KERN_NAME() -> __device__ ncclKernel -> struct RunWorkMSCCL -> run -> RunWorkElement<Fn, T, RedOp, NCCL_ALGO_MSCCL, NCCL_PROTO_LL>() -> runInterpreter -> prims_xxx
- nccl
    * 建图?? TODO: 建什么图, 用来干嘛
        + 建立关系, 方便后期kernel运行的时候使用
