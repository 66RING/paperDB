# Alpa

> 大模型训练无非就是上分布式然后流水并行, 数据并行, 算子并行

基于此作者就发现, 可以可以抽象成两种模式

- 算子间并行(inter-operator)
    * 流水并行
- 算子内并行(intra-operator)
    * 数据并行
    * 张量并行

也就是说一定会有流水并行, 然后每级流水线的任务又分配给多个计算件处理。所以自动并行的搜索就可以分解成两个子问题(不像其他自动并行框架枚举所有模式和可能, e.g. Unity)

1. 先粗粒度的考虑inter-并行(流水并行)
2. 再细粒度的考虑intra-并行(数据并行, 模型并行, Tensor并行)

---

## Alpa实现

盲目的枚举变得有些规则可言, 从而可以使用算法工具搜索

- 两个难点
    * 如何分配流水线: DP动态规划
    * 如何算子拆分: ILP线性规划
- Terms
    * Stage: 计算图的子图 aka 流水线的一个Stage
    * Mesh: 设备的二维逻辑视图, 同一行内高速连通


- ILP: 算子切分聚合的tradeoff
    * 目标: min(通信开销 + 计算开销)
    * 怎么找到模式? **手动枚举80多个算子**, 工程量还ok
    * comm cost = bytes / bandwidth
    * comp cost = 0,
- DP: 流水线怎么划分
    * "assign stage to mesh, and invoke intra pass"
    * 目标: 最小化p2p的流水线的延迟
    * DP找submesh, 物理设备映射上去


intra-op策略算法:

<img src="20230726论文分享img/ILP_f.png" class="ILP_f_img">

- 建模成一个线性函数, 计算开销 + 通信开销 + 形状变换开销

inter-op策略算法:

<img src="20230726论文分享img/DP_f.png" class="DP_f_img">

- F(s, k, d), k个算子划分成s个stage并映射到d个设备的最小开销
- s, k, d三重循环DP


## Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning(OSDI22)

- 优化枚举

> 训练大模型不是ML问题而是OS问题

> 感觉大模型上很多问题在其他领域都有比较成熟的方案了, 就是没有学科交叉的行家来迁移

<!-- 如果细看取得重大突破的大模型如GPT-3, 会发现和5年前的设计差不多，只不过用了更大的模型在更大的数据集上训练。也就是说大模型的突破其实不是归功于ML的突破，而是归功于System上的突破。 -->

<!-- 大部分分布式深度学习系统需要手动设计并行策略，在通用性上存在不足。而现有的自动并行框架能生成的并行策略不多和最优解存在差距。 -->

Alpa就是一个考虑多种并行方式又不引入太多学习成本的框架。

TODO 作者观察到并行如果抽象成intra-并行和inter-并行可以正好对应集群中设备间的层次关系。类似于机器内

基于此，作者将自动并行问题分解成两个子问题：

1. 先粗粒度的考虑inter-并行(流水并行)
2. 再细粒度的考虑intra-并行(数据并行, 模型并行, Tensor并行)

- device mesh
    * 同一mesh内设备算力相同
    * 同一组内通信带宽更高
    * e.g. 两个节点, 每个节点4个GPU, 就有一个两行的mesh逻辑视图, 每行4个设备


- partition
- trade-off, intra, inter, comm, comp
- stratege
    * intra: row, column, replicated, 结合到计算图中
    * inter: 分batch pipeline

- 两个难点
    * 如何划分
    * 如何map到设备

- 如何map, 观察到两层的hierarchy: fast connection, slow connection
    * 两层的hierarchy搜索空间
    * DP, ILP, 剪枝等算法提速
    * inter pass
        + DP
        + intra pass
            + ILP(Integer Linear Programming), 切了就会引入通信(reduce等), 所以做min(comm cost, comp cost)

- 编译时间优化
    * DP, ILP都感知集群和通信延迟
    * 提前停止DP, 趋势不对提前停止
    * 分布式编译, 多机提速
    * 搜索空间剪枝, 跳过相同模式

- Runtime: 编译结果的执行, JAX
    * TODO: the paper
- 测试

- DP
    * assign stage to mesh, and invoke intra pass
    * goal: 最小化p2p的流水线的延迟
    * DP找submesh, 物理设备映射上去
- ILP
    * min(comm cost + comp cost)
    * 怎么找到模式? 手动枚举80多个算子, 工程量还ok
    * comm cost = bytes / bandwidth
    * comp cost = 0,

不管你怎么组合, 反正你最后一定是会做pipeline然后再将每级流水线中的任务分配给多GPU处理。

而Unity则是有点"全局搜索"的感觉, 其pipeline的产生还得靠模式的枚举和变化

全自动和半自动的tradeoff

追求全自动导致他们都必须使用他们自己的runtime, 也许半自动就可以直接在pytorch在原项目上改了

- Terms
    * stage: subgraph
    * mesh: 高速通信
    * group: mesh的集合
    * cross-mesh resharding: tensor形状不一样, 另一个stage的mesh不一样


- 自动找到近似最好, intra-, inter-
- two level hierachy
- effective optimization
- compiler and runtime system

- 复杂而庞大的搜索空间, 通过枚举所有情况的很难找到最优解的
    * alpe通过两层hierachy, 差分搜索空间, 抽象结构和重构
        + 先找inter parallelism plan
        + 再找intra parallelism plan
    * impl
        1. DP找inter
        2. Integer Linear Programming找intra
        3. 代价模型
        4. runtime来识别plan和执行

- [example](https://youtu.be/oVC3SB3GqrI?t=718)
    1. inter pass(form pipeline)
        - 设备映射问题
    2. intra pass
        - ILP问题: TODO怎么个ILP法
            * 每个操作符的并行策略可以抽象成decicion vector in ILP
            * 目标 min(计算开销 + 传输开销)
- 编译时间优化
    * early stop DP, 当没有更好效果时
    * 分布式编译
    * 剪枝
- 单机变多机
    * 同样是要自定义runtime来识别和实现分布式部分的计算图抽象
    * TODO: 30个指令一组??


- 两个挑战
    * 输入很大
    * 模型很大
- intra-, inter-
    * intra传输空闲, 瓶颈在计算
    * inter计算空闲, 瓶颈在传输
- 层次结构的考虑

- 与unity的区别
    * alpa面向更大的模型, 并且auto可以scale
    * TODO: 多机编译

