# idea

- pci call的次数也是可以考虑优化的, group aware

- pipeline ordering
    * idea
        1. 尽可能少让数据跨来跨去
        2. 尽可能最后一级方便
    * impl, 具体有什么好的办法实现呢?
        + 图算法? 割集?
        + 多跳NVLink优于一跳pci的情况该如何智能处理?
    * ref idea
        + WELDER / flash attention: mem hierarchy

## 2023-07-12

### WELDER: Scheduling Deep Learning Memory Access via Tile-graph

论点: 大模型逐渐mem-intensive, 导致计算和mem资源的利用不充分。主打一个利用memory hierarchy

> decompose the whole combinatorial DNN optimization
> space into several independent ones and effectively
> trade off between intra- and inter-operator data reuse using a
> tile **traffic-based cost model**
>
> 可以用来探测独立实践从而插入气泡? 或者更抽象点, pipeline本质就是异步, e.g. Future, 可以自动异步?
> 一种形式同一行的联合优化: dep, 并行... 通过编译器自动生成pipeline(这种需要人为编写的并行方案), 就像rust, 但python中没有语言层面的ast

- observation: 看第二章的3个example
    * e.g. 形状不一致导致不好直接使用共享内存复用(人工手写), 即inter的操作人工构造成本很大。Figure 4
    1. 大致形状是可以根据算子逻辑推到出来的, e.g. nm, mn才能结合
    2. 有了形状就可以计算每次用量和大小, aka **traffic-cost**, 方便做locality的优化等
    3. traffic-cost只依赖算子形状, 无额外依赖方便后续分析

因此得出方法:

aligning a group of
adjacent operators through an output tile shape, deciding on
the best tile shape based on memory traffic, and optimizing
for each memory layer independently. In

- tile-graph: a tile-level data-flow graph to model DNN computation
    * node: process one data tile of a tensor at a time


#### design

1. first-connect-then-schedule 
    - 先假设相邻的算子可以复用数据
    - 再计算最佳的内存布局
    - SetConnect, Propagate
2. two-step scheduling
    - graph connecting + sub-graph scheduling递归搜索执行计划
    - 转换具体代码, 使用四个抽象: Allocate, LoadTiles, ComputeTiles, StoreTiles


#### QA

##### 怎么确定mem layout的？二分搜索?

TODO: Tile propagation?

graph.py::IRNode.propogate
graph.py::IRNode.footprint

##### 代码实现上怎么做reused的? 即怎么组合的。


##### hierarchy是怎么用到? 体现在哪

Figure 5流程:

1. 层层读写
2. 结合成功后生成virtual node



### alpa the paper

论点: 需要自动的分布式ML。

- alpa
    * 视并行为两层: inter-opt, intra-opt


## 2023-07-11

### TICTAC: ACCELERATING DISTRIBUTED DEEP LEARNING WITH COMMUNICATION SCHEDULING

> 又是PS的场景...

根据计算图做通信调度从而加速。根据需求急迫性安排传输顺序(类似byteps的调度器?), 并能实现较好的comm, comp overlap

> base on TensorFlow, what about pytorch?



### PLINK: DISCOVERING AND EXPLOITING DATACENTER NETWORK LOCALITY FOR EFFICIENT CLOUD-BASED DISTRIBUTED TRAINING

探测云中的网络拓扑，生成尽量利用局部性的执行计划。




### BLUECONNECT: DECOMPOSING ALL-REDUCE FOR DEEP LEARNING ON HETEROGENEOUS NETWORK HIERARCHY

主idea: 将一个all-reduce操作分解成多个并行的reduce-scatter和all-gather操作, 然后可以映射到不同网络中以实现拓扑感知(Figure 3, Figure 4)。

> 类似ring和tree的tradeoff?


### alpa source code: pipeline

#### communication algo

#### scheduler

> PipelineSchedule
>
> OverlapFriendlyPipeDreamSchedule

- 调度安排: `schedules.py::OverlapFriendlyPipeDreamSchedule._generate_schedule`中生成
    * 比较难理解的话可以先看Gpipe的实现`GpipeSchedule._generate_schedule`
- 调度使用/部署
    * `CreateStateExecutable -> **PipeshardDriverExecutable** -> **PipeshardMeshWorkerExecutable** -> PipeshardConfig -> PipelineSchedule`
    * `self.fpipeline_plan -> plan_to_method -> PipeshardParallel`
    * `launch_on_driver`


#### communication

> `loadbalance_order_algo`
>
> e.g. LoadBalancingTaskSolverGreedyAlgo

- 执行计划: LoadBalancingTaskSolverGreedyAlgo
- 执行器: ReshardingStrategy
    * tips
        + CrossMeshCommunicator


### ON OPTIMIZING THE COMMUNICATION OF MODEL PARALLELISM

> Alpa中的一部分

提出cross-mesh resharding模式


主要idea/贡献: 1. 一个高效的基于广播的通信系统。2. overlap友好的pipeline

- overlap友好的pipeline
    * Figure 4, 不规则流水线, 非1F1B。(b)中第二行等第三行recv, 这时第二行就可以接着算fw. aka eager-1F1B
    * **在没有通信开销的情况下**, 和1F1B没有区别
    * **而在通信开销的情况下**, 这里就能overlap一点通信, 如Figure 4中第四列
- broadcast-based的通信原语(和算法)
    * observation:
        + Fast intra-node and slow inter-node communication
        + Fully-connected topology between nodes
        + Communication bottleneck at hosts
        + Full duplex



## 2023-07-10

### DATA MOVEMENT IS ALL YOU NEED: A CASE STUDY ON OPTIMIZING TRANSFORMERS

论点: GPU利用率不高，数据传输是主要的瓶颈。通过全局优化数据移动可以提升性能。

- TODO
- 算子融合
- tensor压缩
- TODO

TODO: pass


### PIPEMARE: ASYNCHRONOUS PIPELINE PARALLEL DNN TRAINING

论点: 同步操作等牺牲了硬件性能。在"新硬件"(bubble-free pipeline hardware)的加持下可以做到更高效利用。


- 这些新硬件可以消除上下文切换, 传统kernel by kernel的执行仅存在不停切换的问题

TODO: pass


### PIPELINED BACKPROPAGATION AT SCALE: TRAINING LARGE MODELS WITHOUT BATCHES

论点: 研究了微调流水线对训练的影响, 如batch size等。然后使用SC and LWP两种方法来解决异步导致的精度丢失问题。

TODO: pass





### PipeSwitch: Fast Pipelined Context Switching for Deep Learning Applications

论点: 云服务商提供GPU需要考虑SLO, 因此往往的根据peak做负载均衡这就导致了利用率问题。将其他DL任务插入无用时钟中, 实现分时共享并能只引入微妙级的开销。

主要idea: 利用神经网络分层的结构做pipeline

快在哪: pipelined model transmission, unified memory management, activestandby worker switching.

- Profiling Task Switching Overhead, 切换开销主要来自
    * 清空
    * 初始化
    * 申请内存
    * 加载模型
- pipelined model transmission: 分层分组流水
    * 模型加载受限于PCI
    * 但DL是分层处理的, 也就是说不用整个模型加载完成才开始任务, 加载一个layer后就可以开始
    * 因此，基于DL这种细粒度的执行方式就可以实现流水线: 加载和计算流水
    * 通过在PyTorch中 add hook就可以完成
    * Figure 2 就够了
    * 优化:
        + Optimal model-aware grouping
            + 效果
                - 优化pci调用的次数
                - 并且不是layer level做流水, 因为这样要频繁sync, tradeoff
            - 如何分组:
                * TODO:
                * Algorithm 1 Optimal Model-Aware Grouping
- unified memory management
    * 不用cuda的自动管理, 根据DL任务定制
    * DL中的mem类型
        + 固定大小的
            + 模型
        + 经常变化的
            + 中间结果, 输入输出
    * TODO:
- activestandby worker switching
    * 多进程相互隔离
    * 共享CUDA context
    * TODO:


### ISOSceles: Accelerating Sparse CNNs through Inter-Layer Pipelining

论点: 稀疏CNN减少了内存使用但让数据更密集了, 而如今的加速器处理就成为了瓶颈。这里引入intra pipeline加速

主要idea: 1. 数据压缩减少通信量 2. 划分成边缘图和中心图做并行











