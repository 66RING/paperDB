# idea


# 2023-10-03

## EFFICIENT STREAMING LANGUAGE MODELS WITH ATTENTION SINKS

> 发现滑动窗口attention下的attention sinks现象


- cool
    * 因为自回归反复迭代, 初始输入训练得更好, 因为每次都有他们参与
    * 它们的实验值得学习, **可以通过实验分析perplexity来了解相关性信息**

- idea
    * 那对话类的LLM是不是可以"动态更新initial token"?

- abs
    * 流式应用很好(长对话等), 但是有两个挑战: 1. KVCache显存占用大。2. 预训练好的模型训练的序列长度就是他的上限, 没有外推能力
    * window attention只会缓存最近的KV, 但**作者发现如果缓存初始的KV(tokens)能极大提升性能**, 称为attention sink
        + why? KVCache的位置还能影响计算性能??
            + 但是initial token经过多次自回归迭代, **训练得更好**
            + The reason behind initial tokens as sink tokens is intuitive: initial tokens are visible to almost all subsequent tokens,  **making them more readily trained to serve as attention sinks.**
    * 注意力分数极大地被初始输入给影响了, 即使初始输入在后面没有语法相关, 因此称为"sink"
    * 使用Streaming llm可以让大模型不需要预训练就通用到更长的输入序列, e.g. 4M
    * 如果在预训练时就设计sink的训练(插入空白占位符即可), 效果更好
- 观察
- 设计
    * 位置编码取窗口内的相对距离, 而不是原始token的绝对距离



### QA

- window attension就是**直接放弃之前的输入**?
    * 看起来是的"it results in an exceedingly high language modeling perplexity"
    * 是的, 看Figure 4的箭头
- StreamingLLM exploits the fact that attention sinks have high attention values, and preserving them can maintain the attention score distribution close to normal. 
    * 保留高分有什么用?
- 为什么Streaming这样设计可以?
    * Why do LLMs break when removing initial tokens’ KV? 
        + 什么意思?
        + 两种解释: 结果Table1的实验证明是第二种, 学习了他们的绝对路径
            1. 语法上重要(先有提问再有回答, 所以重点在问题中?)
            2. 模型学到了一些奇怪的模式(他们的绝对路径什么的)
    * 为什么LLM会将初始token看成sink?
        1. 为什么sink会导致这个问题? TOOD
        2. 为什么会有sink? 因为自回归, 考前的序列训练得更多
        3. 所以作者猜测是因为没有统一的起始符





